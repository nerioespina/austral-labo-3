{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26895d69",
   "metadata": {},
   "source": [
    "# ML Forecast con categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477c1bf",
   "metadata": {},
   "source": [
    "## Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlforecast import MLForecast\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from window_ops.rolling import rolling_mean\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from utilsforecast.feature_engineering import fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sell-in.txt', sep='\\t', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos_predecir = pd.read_csv('../data/product_id_apredecir201912.txt', sep='\\t', encoding='utf-8')\n",
    "df_productos_predecir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3790e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['product_id'].isin(df_productos_predecir['product_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['periodo'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a520388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df.pivot_table(\n",
    "    index=['product_id', 'customer_id'],\n",
    "    columns='periodo',\n",
    "    values='tn',\n",
    "    aggfunc='sum',\n",
    "    fill_value=None\n",
    ")\n",
    "df_pivot = df_pivot.reset_index()\n",
    "df_pivot.columns.name = None\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 1. Transformando datos a formato largo ---\")\n",
    "df = df_pivot.melt(\n",
    "    id_vars=['product_id', 'customer_id'],\n",
    "    var_name='periodo',\n",
    "    value_name='y' # MLForecast usa 'y' como nombre de la variable objetivo\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona 10 product_id aleatorios y filtra el dataframe para conservar solo esos productos\n",
    "np.random.seed(42)\n",
    "productos_aleatorios = np.random.choice(df['product_id'].unique(), size=10, replace=False)\n",
    "df = df[df['product_id'].isin(productos_aleatorios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_201912 = df[df['periodo'] == 201912][['product_id', 'customer_id', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_201912.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "FECHA_CORTE = '2019-10-01'\n",
    "horizonte_prediccion = 2\n",
    "product_ids = df['product_id'].unique()\n",
    "df_pred_final = pd.DataFrame()\n",
    "df_best_params = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame para guardar los mejores hiperparámetros de cada serie\n",
    "for pid in product_ids:\n",
    "    df_prod = df[df['product_id'] == pid].copy()\n",
    "    if df_prod.empty:\n",
    "        continue\n",
    "\n",
    "    df_prod['unique_id'] = df_prod['product_id'].astype(str) + \"_\" + df_prod['customer_id'].astype(str)\n",
    "    df_prod['ds'] = pd.to_datetime(df_prod['periodo'], format='%Y%m')\n",
    "    df_prod['y'] = df_prod['y'].fillna(0)\n",
    "    \n",
    "    df_final_prod = df_prod.groupby(['unique_id', 'ds'], as_index=False)['y'].sum()\n",
    "    df_final_prod = df_final_prod.sort_values(by=['unique_id', 'ds']).reset_index(drop=True)\n",
    "    df_entrenamiento_prod = df_final_prod[df_final_prod['ds'] <= FECHA_CORTE]\n",
    "    duplicates = df_entrenamiento_prod.duplicated(subset=['unique_id', 'ds']).sum()\n",
    "    if duplicates > 0:\n",
    "        df_entrenamiento_prod = df_entrenamiento_prod.drop_duplicates(\n",
    "            subset=['unique_id', 'ds'], keep='last'\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        maes = []\n",
    "        for train_idx, val_idx in tscv.split(df_entrenamiento_prod):\n",
    "            train_data = df_entrenamiento_prod.iloc[train_idx].copy()\n",
    "            val_data = df_entrenamiento_prod.iloc[val_idx].copy()\n",
    "            val_data = val_data.drop_duplicates(subset=['unique_id', 'ds'], keep='last')\n",
    "            try:\n",
    "                fcst = MLForecast(\n",
    "                    models=LGBMRegressor(**params),\n",
    "                    freq='MS',\n",
    "                    lags=list(range(1, 25)),\n",
    "                    date_features=['month', 'year'],\n",
    "                )\n",
    "                fcst.fit(train_data, static_features=[])\n",
    "                h = val_data['ds'].nunique()\n",
    "                preds = fcst.predict(h=h)\n",
    "                preds = preds.drop_duplicates(subset=['unique_id', 'ds'], keep='last')\n",
    "                comparison_df = pd.merge(\n",
    "                    val_data, \n",
    "                    preds, \n",
    "                    on=['unique_id', 'ds'], \n",
    "                    how='inner'\n",
    "                )\n",
    "                if len(comparison_df) > 0:\n",
    "                    maes.append(mean_absolute_error(comparison_df['y'], comparison_df['LGBMRegressor']))\n",
    "                else:\n",
    "                    maes.append(1000)\n",
    "            except Exception as e:\n",
    "                maes.append(1000)\n",
    "        return np.mean(maes)\n",
    "\n",
    "    try:\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
    "        best_params = study.best_params\n",
    "        best_params['random_state'] = 42\n",
    "\n",
    "        # Guardar los mejores hiperparámetros en el DataFrame\n",
    "        row = {'product_id': pid}\n",
    "        row.update(best_params)\n",
    "        df_best_params = pd.concat([df_best_params, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        fcst_prod = MLForecast(\n",
    "            models=LGBMRegressor(**best_params),\n",
    "            freq='MS',\n",
    "            lags=list(range(1, 25)),\n",
    "            date_features=['month', 'year'],\n",
    "        )\n",
    "        fcst_prod.fit(df_entrenamiento_prod, static_features=[])\n",
    "        pred_prod = fcst_prod.predict(h=horizonte_prediccion)\n",
    "        pred_prod['product_id'] = pid\n",
    "        pred_prod_201912 = pred_prod[pred_prod['ds'] == '2019-12-01'].copy()\n",
    "        if not pred_prod_201912.empty:\n",
    "            pred_prod_201912['customer_id'] = pred_prod_201912['unique_id'].str.split('_').str[1].astype(int)\n",
    "            pred_prod_201912.rename(columns={'LGBMRegressor': 'tn'}, inplace=True)\n",
    "            df_pred_final = pd.concat([\n",
    "                df_pred_final, \n",
    "                pred_prod_201912[['product_id', 'customer_id', 'tn']]\n",
    "            ], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando product_id {pid}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Resumen final\n",
    "if not df_pred_final.empty:\n",
    "    df_pred_sum = df_pred_final.groupby('product_id', as_index=False)['tn'].sum()\n",
    "    print(df_pred_sum)\n",
    "else:\n",
    "    print(\"No se generaron predicciones\")\n",
    "\n",
    "# Mostrar los mejores hiperparámetros por serie\n",
    "print(df_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_real_201912.shape, df_pred_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el error cuadrático medio (MSE) entre las predicciones y los valores reales\n",
    "# Para esto, necesitamos los valores reales correspondientes a las predicciones\n",
    "\n",
    "# Unimos las predicciones con los valores reales\n",
    "df_eval = pd.merge(df_pred_final, df_real_201912, on=['product_id', 'customer_id'], how='inner')\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse = mean_squared_error(df_eval['y'].fillna(0), df_eval['tn'].fillna(0))\n",
    "print(f'Error cuadrático medio (MSE): {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_params.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b12f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_params.to_csv('df_best_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "FECHA_CORTE = '2019-12-01'\n",
    "horizonte_prediccion = 2  # enero y febrero 2020\n",
    "\n",
    "product_ids = df['product_id'].unique()\n",
    "df_pred_final = pd.DataFrame()\n",
    "\n",
    "for pid in product_ids:\n",
    "    # Obtener los mejores hiperparámetros para el producto actual\n",
    "    params_row = df_best_params[df_best_params['product_id'] == pid]\n",
    "    if params_row.empty:\n",
    "        print(f\"No se encontraron hiperparámetros para el product_id {pid}. Saltando.\")\n",
    "        continue\n",
    "    \n",
    "    best_params_prod = params_row.drop(columns=['product_id']).to_dict('records')[0]\n",
    "    \n",
    "    # Asegurar que los parámetros que deben ser enteros lo sean\n",
    "    for p in ['num_leaves', 'max_depth', 'n_estimators']:\n",
    "        if p in best_params_prod:\n",
    "            best_params_prod[p] = int(best_params_prod[p])\n",
    "\n",
    "    df_prod = df[df['product_id'] == pid].copy()\n",
    "    if df_prod.empty:\n",
    "        continue\n",
    "\n",
    "    df_prod['unique_id'] = df_prod['product_id'].astype(str) + \"_\" + df_prod['customer_id'].astype(str)\n",
    "    df_prod['ds'] = pd.to_datetime(df_prod['periodo'], format='%Y%m')\n",
    "    df_prod['y'] = df_prod['y'].fillna(0)\n",
    "    df_final_prod = df_prod[['unique_id', 'ds', 'y']].sort_values(by=['unique_id', 'ds']).reset_index(drop=True)\n",
    "    df_final_prod = df_final_prod.loc[:, ~df_final_prod.columns.duplicated()]\n",
    "    df_entrenamiento_prod = df_final_prod[df_final_prod['ds'] <= FECHA_CORTE]\n",
    "\n",
    "    fcst_prod = MLForecast(\n",
    "        models=LGBMRegressor(**best_params_prod),\n",
    "        freq='MS',\n",
    "        lags=list(range(1, 25)),\n",
    "        date_features=['month', 'year'],\n",
    "    )\n",
    "    fcst_prod.fit(df_entrenamiento_prod, static_features=[])\n",
    "\n",
    "    pred_prod = fcst_prod.predict(h=horizonte_prediccion)\n",
    "    pred_prod['product_id'] = pid\n",
    "\n",
    "    pred_prod_202002 = pred_prod[pred_prod['ds'] == '2020-02-01'].copy()\n",
    "    if not pred_prod_202002.empty:\n",
    "        pred_prod_202002['customer_id'] = pred_prod_202002['unique_id'].str.split('_').str[1].astype(int)\n",
    "        pred_prod_202002.rename(columns={'LGBMRegressor': 'tn'}, inplace=True)\n",
    "\n",
    "        df_pred_final = pd.concat([df_pred_final, pred_prod_202002[['product_id', 'customer_id', 'tn']]], ignore_index=True)\n",
    "\n",
    "if not df_pred_final.empty:\n",
    "    df_pred_sum = df_pred_final.groupby('product_id', as_index=False)['tn'].sum()\n",
    "    print(df_pred_sum)\n",
    "else:\n",
    "    print(\"No se generaron predicciones para febrero de 2020.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sum.to_csv('df_pred_sum_b.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
