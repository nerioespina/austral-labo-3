{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854465b0",
   "metadata": {},
   "source": [
    "# Construcci√≥n del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9007d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nespina/Elements/maestriacd/austral/labo_3/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlforecast import MLForecast\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from window_ops.rolling import rolling_mean\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from utilsforecast.feature_engineering import fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7c9286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701        10234       20524                      0                 2   \n",
       "1   201701        10032       20524                      0                 1   \n",
       "2   201701        10217       20524                      0                 1   \n",
       "3   201701        10125       20524                      0                 1   \n",
       "4   201701        10012       20524                      0                11   \n",
       "\n",
       "   cust_request_tn       tn  \n",
       "0          0.05300  0.05300  \n",
       "1          0.13628  0.13628  \n",
       "2          0.03028  0.03028  \n",
       "3          0.02271  0.02271  \n",
       "4          1.54452  1.54452  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/sell-in.txt', sep='\\t', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7484795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0       20001\n",
       "1       20002\n",
       "2       20003\n",
       "3       20004\n",
       "4       20005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos_predecir = pd.read_csv('../data/product_id_apredecir201912.txt', sep='\\t', encoding='utf-8')\n",
    "df_productos_predecir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1451c712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201701, 201702, 201703, 201704, 201705, 201706, 201707, 201708,\n",
       "       201709, 201710, 201711, 201712, 201801, 201802, 201803, 201804,\n",
       "       201805, 201806, 201807, 201808, 201809, 201810, 201811, 201812,\n",
       "       201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['periodo'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a389d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>201701</th>\n",
       "      <th>201702</th>\n",
       "      <th>201703</th>\n",
       "      <th>201704</th>\n",
       "      <th>201705</th>\n",
       "      <th>201706</th>\n",
       "      <th>201707</th>\n",
       "      <th>201708</th>\n",
       "      <th>...</th>\n",
       "      <th>201903</th>\n",
       "      <th>201904</th>\n",
       "      <th>201905</th>\n",
       "      <th>201906</th>\n",
       "      <th>201907</th>\n",
       "      <th>201908</th>\n",
       "      <th>201909</th>\n",
       "      <th>201910</th>\n",
       "      <th>201911</th>\n",
       "      <th>201912</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>198.84365</td>\n",
       "      <td>92.46537</td>\n",
       "      <td>13.29728</td>\n",
       "      <td>101.00563</td>\n",
       "      <td>128.04792</td>\n",
       "      <td>101.20711</td>\n",
       "      <td>43.33930</td>\n",
       "      <td>...</td>\n",
       "      <td>130.54927</td>\n",
       "      <td>364.37071</td>\n",
       "      <td>439.90647</td>\n",
       "      <td>65.92436</td>\n",
       "      <td>144.78714</td>\n",
       "      <td>33.63991</td>\n",
       "      <td>109.05244</td>\n",
       "      <td>176.02980</td>\n",
       "      <td>236.65556</td>\n",
       "      <td>180.21938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>10002</td>\n",
       "      <td>35.72806</td>\n",
       "      <td>6.79415</td>\n",
       "      <td>29.94128</td>\n",
       "      <td>22.81133</td>\n",
       "      <td>31.22847</td>\n",
       "      <td>47.57025</td>\n",
       "      <td>21.84874</td>\n",
       "      <td>17.08052</td>\n",
       "      <td>...</td>\n",
       "      <td>31.97079</td>\n",
       "      <td>55.41679</td>\n",
       "      <td>30.87299</td>\n",
       "      <td>144.07021</td>\n",
       "      <td>37.14616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.08551</td>\n",
       "      <td>17.40806</td>\n",
       "      <td>45.61495</td>\n",
       "      <td>113.33165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>10003</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>20.48319</td>\n",
       "      <td>137.87537</td>\n",
       "      <td>68.89292</td>\n",
       "      <td>135.12190</td>\n",
       "      <td>171.01785</td>\n",
       "      <td>64.66196</td>\n",
       "      <td>83.63410</td>\n",
       "      <td>...</td>\n",
       "      <td>170.89924</td>\n",
       "      <td>230.00152</td>\n",
       "      <td>1.84835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.23391</td>\n",
       "      <td>162.07198</td>\n",
       "      <td>233.20532</td>\n",
       "      <td>76.00625</td>\n",
       "      <td>86.14415</td>\n",
       "      <td>102.27517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>10004</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>104.03894</td>\n",
       "      <td>295.43924</td>\n",
       "      <td>247.65632</td>\n",
       "      <td>188.37819</td>\n",
       "      <td>195.02683</td>\n",
       "      <td>379.44270</td>\n",
       "      <td>237.16848</td>\n",
       "      <td>...</td>\n",
       "      <td>102.64484</td>\n",
       "      <td>91.67799</td>\n",
       "      <td>389.02653</td>\n",
       "      <td>66.71971</td>\n",
       "      <td>228.62366</td>\n",
       "      <td>96.11402</td>\n",
       "      <td>288.34205</td>\n",
       "      <td>324.96172</td>\n",
       "      <td>195.67828</td>\n",
       "      <td>34.64810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>10005</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>5.17117</td>\n",
       "      <td>5.17117</td>\n",
       "      <td>0.86186</td>\n",
       "      <td>37.95546</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>43.35049</td>\n",
       "      <td>67.53856</td>\n",
       "      <td>...</td>\n",
       "      <td>6.90049</td>\n",
       "      <td>22.18016</td>\n",
       "      <td>15.89578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.25595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.80400</td>\n",
       "      <td>17.13921</td>\n",
       "      <td>12.22149</td>\n",
       "      <td>19.60368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id     201701     201702     201703     201704  \\\n",
       "0       20001        10001   99.43861  198.84365   92.46537   13.29728   \n",
       "1       20001        10002   35.72806    6.79415   29.94128   22.81133   \n",
       "2       20001        10003  143.49426   20.48319  137.87537   68.89292   \n",
       "3       20001        10004  184.72927  104.03894  295.43924  247.65632   \n",
       "4       20001        10005   19.08407    5.17117    5.17117    0.86186   \n",
       "\n",
       "      201705     201706     201707     201708  ...     201903     201904  \\\n",
       "0  101.00563  128.04792  101.20711   43.33930  ...  130.54927  364.37071   \n",
       "1   31.22847   47.57025   21.84874   17.08052  ...   31.97079   55.41679   \n",
       "2  135.12190  171.01785   64.66196   83.63410  ...  170.89924  230.00152   \n",
       "3  188.37819  195.02683  379.44270  237.16848  ...  102.64484   91.67799   \n",
       "4   37.95546   19.08407   43.35049   67.53856  ...    6.90049   22.18016   \n",
       "\n",
       "      201905     201906     201907     201908     201909     201910  \\\n",
       "0  439.90647   65.92436  144.78714   33.63991  109.05244  176.02980   \n",
       "1   30.87299  144.07021   37.14616        NaN   72.08551   17.40806   \n",
       "2    1.84835        NaN  138.23391  162.07198  233.20532   76.00625   \n",
       "3  389.02653   66.71971  228.62366   96.11402  288.34205  324.96172   \n",
       "4   15.89578        NaN    8.25595        NaN   12.80400   17.13921   \n",
       "\n",
       "      201911     201912  \n",
       "0  236.65556  180.21938  \n",
       "1   45.61495  113.33165  \n",
       "2   86.14415  102.27517  \n",
       "3  195.67828   34.64810  \n",
       "4   12.22149   19.60368  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = df.pivot_table(\n",
    "    index=['product_id', 'customer_id'],\n",
    "    columns='periodo',\n",
    "    values='tn',\n",
    "    aggfunc='sum',\n",
    "    fill_value=None\n",
    ")\n",
    "df_pivot = df_pivot.reset_index()\n",
    "df_pivot.columns.name = None\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd248f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove from df_pivot the products that are not in df_productos_predecir\n",
    "df_pivot = df_pivot[df_pivot['product_id'].isin(df_productos_predecir['product_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a739983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mlforecast = df_pivot[df_pivot['customer_id'] == 10001].copy()\n",
    "df_mlforecast = df_pivot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad357bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>201701</th>\n",
       "      <th>201702</th>\n",
       "      <th>201703</th>\n",
       "      <th>201704</th>\n",
       "      <th>201705</th>\n",
       "      <th>201706</th>\n",
       "      <th>201707</th>\n",
       "      <th>201708</th>\n",
       "      <th>...</th>\n",
       "      <th>201903</th>\n",
       "      <th>201904</th>\n",
       "      <th>201905</th>\n",
       "      <th>201906</th>\n",
       "      <th>201907</th>\n",
       "      <th>201908</th>\n",
       "      <th>201909</th>\n",
       "      <th>201910</th>\n",
       "      <th>201911</th>\n",
       "      <th>201912</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>198.84365</td>\n",
       "      <td>92.46537</td>\n",
       "      <td>13.29728</td>\n",
       "      <td>101.00563</td>\n",
       "      <td>128.04792</td>\n",
       "      <td>101.20711</td>\n",
       "      <td>43.33930</td>\n",
       "      <td>...</td>\n",
       "      <td>130.54927</td>\n",
       "      <td>364.37071</td>\n",
       "      <td>439.90647</td>\n",
       "      <td>65.92436</td>\n",
       "      <td>144.78714</td>\n",
       "      <td>33.63991</td>\n",
       "      <td>109.05244</td>\n",
       "      <td>176.02980</td>\n",
       "      <td>236.65556</td>\n",
       "      <td>180.21938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>10002</td>\n",
       "      <td>35.72806</td>\n",
       "      <td>6.79415</td>\n",
       "      <td>29.94128</td>\n",
       "      <td>22.81133</td>\n",
       "      <td>31.22847</td>\n",
       "      <td>47.57025</td>\n",
       "      <td>21.84874</td>\n",
       "      <td>17.08052</td>\n",
       "      <td>...</td>\n",
       "      <td>31.97079</td>\n",
       "      <td>55.41679</td>\n",
       "      <td>30.87299</td>\n",
       "      <td>144.07021</td>\n",
       "      <td>37.14616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.08551</td>\n",
       "      <td>17.40806</td>\n",
       "      <td>45.61495</td>\n",
       "      <td>113.33165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>10003</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>20.48319</td>\n",
       "      <td>137.87537</td>\n",
       "      <td>68.89292</td>\n",
       "      <td>135.12190</td>\n",
       "      <td>171.01785</td>\n",
       "      <td>64.66196</td>\n",
       "      <td>83.63410</td>\n",
       "      <td>...</td>\n",
       "      <td>170.89924</td>\n",
       "      <td>230.00152</td>\n",
       "      <td>1.84835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.23391</td>\n",
       "      <td>162.07198</td>\n",
       "      <td>233.20532</td>\n",
       "      <td>76.00625</td>\n",
       "      <td>86.14415</td>\n",
       "      <td>102.27517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>10004</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>104.03894</td>\n",
       "      <td>295.43924</td>\n",
       "      <td>247.65632</td>\n",
       "      <td>188.37819</td>\n",
       "      <td>195.02683</td>\n",
       "      <td>379.44270</td>\n",
       "      <td>237.16848</td>\n",
       "      <td>...</td>\n",
       "      <td>102.64484</td>\n",
       "      <td>91.67799</td>\n",
       "      <td>389.02653</td>\n",
       "      <td>66.71971</td>\n",
       "      <td>228.62366</td>\n",
       "      <td>96.11402</td>\n",
       "      <td>288.34205</td>\n",
       "      <td>324.96172</td>\n",
       "      <td>195.67828</td>\n",
       "      <td>34.64810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>10005</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>5.17117</td>\n",
       "      <td>5.17117</td>\n",
       "      <td>0.86186</td>\n",
       "      <td>37.95546</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>43.35049</td>\n",
       "      <td>67.53856</td>\n",
       "      <td>...</td>\n",
       "      <td>6.90049</td>\n",
       "      <td>22.18016</td>\n",
       "      <td>15.89578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.25595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.80400</td>\n",
       "      <td>17.13921</td>\n",
       "      <td>12.22149</td>\n",
       "      <td>19.60368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id     201701     201702     201703     201704  \\\n",
       "0       20001        10001   99.43861  198.84365   92.46537   13.29728   \n",
       "1       20001        10002   35.72806    6.79415   29.94128   22.81133   \n",
       "2       20001        10003  143.49426   20.48319  137.87537   68.89292   \n",
       "3       20001        10004  184.72927  104.03894  295.43924  247.65632   \n",
       "4       20001        10005   19.08407    5.17117    5.17117    0.86186   \n",
       "\n",
       "      201705     201706     201707     201708  ...     201903     201904  \\\n",
       "0  101.00563  128.04792  101.20711   43.33930  ...  130.54927  364.37071   \n",
       "1   31.22847   47.57025   21.84874   17.08052  ...   31.97079   55.41679   \n",
       "2  135.12190  171.01785   64.66196   83.63410  ...  170.89924  230.00152   \n",
       "3  188.37819  195.02683  379.44270  237.16848  ...  102.64484   91.67799   \n",
       "4   37.95546   19.08407   43.35049   67.53856  ...    6.90049   22.18016   \n",
       "\n",
       "      201905     201906     201907     201908     201909     201910  \\\n",
       "0  439.90647   65.92436  144.78714   33.63991  109.05244  176.02980   \n",
       "1   30.87299  144.07021   37.14616        NaN   72.08551   17.40806   \n",
       "2    1.84835        NaN  138.23391  162.07198  233.20532   76.00625   \n",
       "3  389.02653   66.71971  228.62366   96.11402  288.34205  324.96172   \n",
       "4   15.89578        NaN    8.25595        NaN   12.80400   17.13921   \n",
       "\n",
       "      201911     201912  \n",
       "0  236.65556  180.21938  \n",
       "1   45.61495  113.33165  \n",
       "2   86.14415  102.27517  \n",
       "3  195.67828   34.64810  \n",
       "4   12.22149   19.60368  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlforecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258653b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Transformando datos a formato largo ---\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 1: TRANSFORMACI√ìN DE DATOS A FORMATO LARGO ---\n",
    "# Este es el formato conveniente que usaremos en ambos casos.\n",
    "print(\"\\n--- 1. Transformando datos a formato largo ---\")\n",
    "df_long = df_mlforecast.melt(\n",
    "    id_vars=['product_id', 'customer_id'],\n",
    "    var_name='periodo',\n",
    "    value_name='y' # MLForecast usa 'y' como nombre de la variable objetivo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85af9b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201701</td>\n",
       "      <td>99.43861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>10002</td>\n",
       "      <td>201701</td>\n",
       "      <td>35.72806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>10003</td>\n",
       "      <td>201701</td>\n",
       "      <td>143.49426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>10004</td>\n",
       "      <td>201701</td>\n",
       "      <td>184.72927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>10005</td>\n",
       "      <td>201701</td>\n",
       "      <td>19.08407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id periodo          y\n",
       "0       20001        10001  201701   99.43861\n",
       "1       20001        10002  201701   35.72806\n",
       "2       20001        10003  201701  143.49426\n",
       "3       20001        10004  201701  184.72927\n",
       "4       20001        10005  201701   19.08407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efb215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar todos los DataFrames para conservar solo los registros con customer_id 10001\n",
    "# df_long = df_long[df_long['customer_id'] == 10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a184ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_695331/3730884332.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_long = df_long.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de datos listo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>99.43861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>198.84365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>92.46537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>13.29728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>101.00563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds          y\n",
       "0  20001_10001 2017-01-01   99.43861\n",
       "1  20001_10001 2017-02-01  198.84365\n",
       "2  20001_10001 2017-03-01   92.46537\n",
       "3  20001_10001 2017-04-01   13.29728\n",
       "4  20001_10001 2017-05-01  101.00563"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df_long.fillna(0)\n",
    "# Creamos las columnas que MLForecast requiere: unique_id, ds, y\n",
    "df_long['unique_id'] = df_long['product_id'].astype(str) + \"_\" + df_long['customer_id'].astype(str)\n",
    "df_long['ds'] = pd.to_datetime(df_long['periodo'], format='%Y%m')\n",
    "\n",
    "# Seleccionamos y ordenamos las columnas finales\n",
    "df_final = df_long[['unique_id', 'ds', 'y']].sort_values(by=['unique_id', 'ds']).reset_index(drop=True)\n",
    "print(\"Formato de datos listo:\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8291b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcst = MLForecast(\n",
    "#     models=[\n",
    "#         LGBMRegressor(\n",
    "#             random_state=42,\n",
    "#             n_estimators=132,\n",
    "#             learning_rate=0.0425038112097633,\n",
    "#             num_leaves=83,\n",
    "#             max_depth=3,\n",
    "#             min_child_samples=18,\n",
    "#             subsample=0.8823228364012079,\n",
    "#             colsample_bytree=0.7618871571728139\n",
    "#         )\n",
    "#     ],\n",
    "#     freq='MS',\n",
    "#     lags=[1, 2, 3, 6, 12],\n",
    "#     lag_transforms={\n",
    "#         1: [(rolling_mean, 3), (rolling_mean, 6)],\n",
    "#         3: [(rolling_mean, 3)]\n",
    "#     },\n",
    "#     date_features=['month', 'year', 'dayofweek']\n",
    "# )\n",
    "\n",
    "# fcst = MLForecast(\n",
    "#     models=LGBMRegressor(random_state=42, n_estimators=100),\n",
    "#     freq='MS',\n",
    "#     lags=[1, 2, 3, 6, 12], # <-- Lag estacional de 12 meses\n",
    "#     date_features=['month', 'quarter', 'year'], # <-- Features de fecha\n",
    "#     target_transforms=[\n",
    "#         fourier(\n",
    "#             df=df_entrenamiento,\n",
    "#             freq='M', \n",
    "#             season_length=12,\n",
    "#             k=12)\n",
    "#     ] # <-- Features de Fourier\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04fd3b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Creando features de Fourier ---\n",
      "Datos de entrenamiento hasta: 2019-10-01\n",
      "--- 3. Entrenando el modelo ---\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.196680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2476\n",
      "[LightGBM] [Info] Number of data points in the train set: 5781710, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.114956\n",
      "Modelo entrenado.\n",
      "--- 4. Creando features futuros para la predicci√≥n ---\n",
      "--- Reconstruyendo features categ√≥ricos en el DataFrame futuro ---\n",
      "--- 5. Realizando la predicci√≥n ---\n",
      "--- 6. Comparando resultados ---\n",
      "\n",
      "--- Comparaci√≥n: Valor Real vs. Predicci√≥n (Simulaci√≥n) ---\n",
      "          unique_id         ds  Valor_Real  Prediccion\n",
      "0       20001_10001 2019-11-01   236.65556   12.493757\n",
      "1       20001_10001 2019-12-01   180.21938   13.993288\n",
      "2       20001_10002 2019-11-01    45.61495    9.966709\n",
      "3       20001_10002 2019-12-01   113.33165   14.723716\n",
      "4       20001_10003 2019-11-01    86.14415   13.221413\n",
      "...             ...        ...         ...         ...\n",
      "525605  21276_10462 2019-12-01     0.00000    0.007476\n",
      "525606  21276_10495 2019-11-01     0.00000    0.005161\n",
      "525607  21276_10495 2019-12-01     0.00000    0.007476\n",
      "525608  21276_10550 2019-11-01     0.00371    0.005161\n",
      "525609  21276_10550 2019-12-01     0.00000    0.007476\n",
      "\n",
      "[525610 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Creando features de Fourier correctamente\n",
    "print(\"--- 1. Creando features de Fourier ---\")\n",
    "# La funci√≥n fourier necesita la serie de fechas, no el DataFrame completo.\n",
    "# Y devuelve un DataFrame, no una tupla.\n",
    "fourier_features = fourier(df=df_final, freq='MS', season_length=12, k=12, time_col='ds')\n",
    "df_final = pd.concat([df_final, fourier_features[0]], axis=1)\n",
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()] # Buena pr√°ctica\n",
    "\n",
    "# 2. Dividir los datos\n",
    "FECHA_CORTE = '2019-10-01'\n",
    "df_entrenamiento = df_final[df_final['ds'] <= FECHA_CORTE]\n",
    "df_validacion = df_final[df_final['ds'] > FECHA_CORTE]\n",
    "print(f\"Datos de entrenamiento hasta: {df_entrenamiento['ds'].max().date()}\")\n",
    "\n",
    "# 3. Configurar y entrenar el modelo\n",
    "print(\"--- 3. Entrenando el modelo ---\")\n",
    "fcst = MLForecast(\n",
    "    models=LGBMRegressor(random_state=42, n_estimators=100),\n",
    "    freq='MS',\n",
    "    lags=[1, 2, 3, 6, 12],\n",
    "    date_features=['month', 'year'],\n",
    ")\n",
    "# El modelo aprende de TODAS las columnas en df_entrenamiento, incluyendo las de Fourier\n",
    "fcst.fit(df_entrenamiento, static_features=[])\n",
    "print(\"Modelo entrenado.\")\n",
    "\n",
    "# 4. Crear el DataFrame de Features Futuros (X_df) - ¬°EL PASO CLAVE QUE FALTABA!\n",
    "print(\"--- 4. Creando features futuros para la predicci√≥n ---\")\n",
    "horizonte_prediccion = 2\n",
    "last_date = df_entrenamiento['ds'].max()\n",
    "future_dates = pd.date_range(last_date, periods=horizonte_prediccion + 1, freq='MS')[1:]\n",
    "\n",
    "# Creamos el DataFrame futuro con las columnas 'unique_id' y 'ds'\n",
    "future_df = pd.DataFrame({\n",
    "    'unique_id': np.repeat(df_entrenamiento['unique_id'].unique(), horizonte_prediccion),\n",
    "    'ds': np.tile(future_dates, df_entrenamiento['unique_id'].nunique())\n",
    "})\n",
    "# AJUSTE 3: RECONSTRUIMOS las columnas categ√≥ricas en el DataFrame futuro\n",
    "print(\"--- Reconstruyendo features categ√≥ricos en el DataFrame futuro ---\")\n",
    "future_df['product_id'] = future_df['unique_id'].str.split('_').str[0].astype('category')\n",
    "\n",
    "# Calculamos los features de Fourier para esas fechas futuras\n",
    "future_fourier_features = fourier(df=future_df, freq='MS', season_length=12, k=12, time_col='ds')\n",
    "# Unimos los features al DataFrame futuro. Ahora tiene la misma estructura que los datos de entrenamiento.\n",
    "future_df = pd.concat([future_df, future_fourier_features[0]], axis=1)\n",
    "future_df = future_df.loc[:, ~future_df.columns.duplicated()]\n",
    "\n",
    "# 5. Predecir usando el horizonte (h) y el DataFrame de features futuros (X_df)\n",
    "print(\"--- 5. Realizando la predicci√≥n ---\")\n",
    "predicciones_simulacion = fcst.predict(h=horizonte_prediccion, X_df=future_df)\n",
    "\n",
    "# 6. Comparar la predicci√≥n con los valores reales\n",
    "print(\"--- 6. Comparando resultados ---\")\n",
    "resultados_validacion = pd.merge(\n",
    "    df_validacion,\n",
    "    predicciones_simulacion,\n",
    "    on=['unique_id', 'ds']\n",
    ")\n",
    "print(\"\\n--- Comparaci√≥n: Valor Real vs. Predicci√≥n (Simulaci√≥n) ---\")\n",
    "# Mostramos solo las columnas relevantes para la comparaci√≥n\n",
    "print(resultados_validacion[['unique_id', 'ds', 'y', 'LGBMRegressor']].rename(columns={'y': 'Valor_Real', 'LGBMRegressor': 'Prediccion'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " PARTE 1: SIMULACI√ìN Y VALIDACI√ìN\n",
      "============================================================\n",
      "\n",
      "Datos de entrenamiento: 8935370 filas, hasta la fecha 2019-10-01\n",
      "Datos de validaci√≥n: 525610 filas, desde la fecha 2019-11-01\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.156060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 5781710, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.114956\n",
      "\n",
      "--- Comparaci√≥n: Valor Real vs. Predicci√≥n (Simulaci√≥n) ---\n",
      "          unique_id         ds  Valor_Real  Prediccion\n",
      "0       20001_10001 2019-11-01   236.65556   85.167816\n",
      "1       20001_10001 2019-12-01   180.21938   80.003993\n",
      "2       20001_10002 2019-11-01    45.61495   14.402763\n",
      "3       20001_10002 2019-12-01   113.33165   26.585248\n",
      "4       20001_10003 2019-11-01    86.14415   53.356966\n",
      "...             ...        ...         ...         ...\n",
      "525605  21276_10462 2019-12-01     0.00000    0.007584\n",
      "525606  21276_10495 2019-11-01     0.00000    0.009979\n",
      "525607  21276_10495 2019-12-01     0.00000    0.007584\n",
      "525608  21276_10550 2019-11-01     0.00371    0.009979\n",
      "525609  21276_10550 2019-12-01     0.00000    0.007584\n",
      "\n",
      "[525610 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PARTE 1: SIMULACI√ìN Y VALIDACI√ìN (Predecir 201912 con datos hasta 201910)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" PARTE 1: SIMULACI√ìN Y VALIDACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# 3. Dividimos los datos: entrenamiento hasta 2019-10, validaci√≥n despu√©s.\n",
    "FECHA_CORTE = '2019-10-01'\n",
    "# Elimina columnas duplicadas antes de dividir en entrenamiento y validaci√≥n\n",
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()]\n",
    "\n",
    "df_entrenamiento = df_final[df_final['ds'] <= FECHA_CORTE]\n",
    "df_validacion = df_final[df_final['ds'] > FECHA_CORTE]\n",
    "\n",
    "print(f\"\\nDatos de entrenamiento: {df_entrenamiento.shape[0]} filas, hasta la fecha {df_entrenamiento['ds'].max().date()}\")\n",
    "print(f\"Datos de validaci√≥n: {df_validacion.shape[0]} filas, desde la fecha {df_validacion['ds'].min().date()}\")\n",
    "\n",
    "# 4. Configurar y entrenar el modelo MLForecast\n",
    "#    - lags: Usamos lags de hasta 12 meses para capturar estacionalidad anual.\n",
    "#      Es crucial tener lags >= al horizonte de predicci√≥n (h).\n",
    "#    - lag_transforms: Creamos medias m√≥viles para suavizar la serie.\n",
    "#    - date_features: El mes y el a√±o son caracter√≠sticas muy √∫tiles.\n",
    "# Mejor combinaci√≥n de hiperpar√°metros encontrada (ejemplo, debes ajustar seg√∫n validaci√≥n real)\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models=LGBMRegressor(random_state=42, n_estimators=100),\n",
    "    freq='MS',\n",
    "    lags=[1, 2, 3, 6, 12],\n",
    "    date_features=['month', 'year'],\n",
    ")\n",
    "# Entrenamos el modelo SOLO con los datos de entrenamiento\n",
    "fcst.fit(df_entrenamiento, static_features=[])\n",
    "\n",
    "# 5. Predecir 2 pasos hacia adelante (h=2) para obtener 201911 y 201912\n",
    "# MLForecast sabe que debe empezar a predecir despu√©s de la √∫ltima fecha de entrenamiento.\n",
    "horizonte_prediccion = 2\n",
    "\n",
    "predicciones_simulacion = fcst.predict(h=horizonte_prediccion)\n",
    "\n",
    "# 6. Comparar la predicci√≥n con los valores reales\n",
    "# Unimos las predicciones con los datos reales de validaci√≥n para comparar.\n",
    "resultados_validacion = pd.merge(\n",
    "    df_validacion,\n",
    "    predicciones_simulacion,\n",
    "    on=['unique_id', 'ds']\n",
    ")\n",
    "print(\"\\n--- Comparaci√≥n: Valor Real vs. Predicci√≥n (Simulaci√≥n) ---\")\n",
    "print(resultados_validacion.rename(columns={'y': 'Valor_Real', 'LGBMRegressor': 'Prediccion'}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6340dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # Optimizaci√≥n de Hiperpar√°metros con Optuna\n",
    "# # ==============================================================================\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\" PARTE 1: SIMULACI√ìN Y VALIDACI√ìN\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # 3. Dividimos los datos: entrenamiento hasta 2019-10, validaci√≥n despu√©s.\n",
    "# FECHA_CORTE = '2019-10-01'\n",
    "# df_entrenamiento = df_final[df_final['ds'] <= FECHA_CORTE]\n",
    "# df_validacion = df_final[df_final['ds'] > FECHA_CORTE]\n",
    "\n",
    "# horizonte_prediccion = 2\n",
    "\n",
    "# print(f\"\\nDatos de entrenamiento: {df_entrenamiento.shape[0]} filas, hasta la fecha {df_entrenamiento['ds'].max().date()}\")\n",
    "# print(f\"Datos de validaci√≥n: {df_validacion.shape[0]} filas, desde la fecha {df_validacion['ds'].min().date()}\")\n",
    "\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "#     model = LGBMRegressor(**params)\n",
    "#     fcst = MLForecast(\n",
    "#         models=[model],\n",
    "#         freq='MS',\n",
    "#         lags=[1, 2, 3, 6, 12],\n",
    "#         lag_transforms={\n",
    "#             1: [(rolling_mean, 3), (rolling_mean, 6)],\n",
    "#             3: [(rolling_mean, 3)]\n",
    "#         },\n",
    "#         date_features=['month', 'year', 'dayofweek']\n",
    "#     )\n",
    "#     # Entrenamiento y validaci√≥n\n",
    "#     fcst.fit(df_entrenamiento)\n",
    "#     preds = fcst.predict(h=horizonte_prediccion)\n",
    "#     merged = pd.merge(df_validacion, preds, on=['unique_id', 'ds'])\n",
    "#     score = mean_absolute_error(merged['y'], merged['LGBMRegressor'])\n",
    "#     return score\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# print(\"Mejores hiperpar√°metros encontrados:\")\n",
    "# print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd772d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>sin1_12</th>\n",
       "      <th>sin2_12</th>\n",
       "      <th>sin3_12</th>\n",
       "      <th>sin4_12</th>\n",
       "      <th>sin5_12</th>\n",
       "      <th>sin6_12</th>\n",
       "      <th>sin7_12</th>\n",
       "      <th>...</th>\n",
       "      <th>cos4_12</th>\n",
       "      <th>cos5_12</th>\n",
       "      <th>cos6_12</th>\n",
       "      <th>cos7_12</th>\n",
       "      <th>cos8_12</th>\n",
       "      <th>cos9_12</th>\n",
       "      <th>cos10_12</th>\n",
       "      <th>cos11_12</th>\n",
       "      <th>cos12_12</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>236.65556</td>\n",
       "      <td>-4.999990e-01</td>\n",
       "      <td>-8.660243e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-8.660276e-01</td>\n",
       "      <td>-4.999982e-01</td>\n",
       "      <td>-6.636076e-06</td>\n",
       "      <td>0.500006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499996</td>\n",
       "      <td>-0.866026</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.866022</td>\n",
       "      <td>-0.500008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.866027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.923027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>180.21938</td>\n",
       "      <td>4.769952e-08</td>\n",
       "      <td>9.539905e-08</td>\n",
       "      <td>1.430986e-07</td>\n",
       "      <td>1.907981e-07</td>\n",
       "      <td>2.384976e-07</td>\n",
       "      <td>2.861971e-07</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.890963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001_10002</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>45.61495</td>\n",
       "      <td>-4.999990e-01</td>\n",
       "      <td>-8.660243e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-8.660276e-01</td>\n",
       "      <td>-4.999982e-01</td>\n",
       "      <td>-6.636076e-06</td>\n",
       "      <td>0.500006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499996</td>\n",
       "      <td>-0.866026</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.866022</td>\n",
       "      <td>-0.500008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.866027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001_10002</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>113.33165</td>\n",
       "      <td>4.769952e-08</td>\n",
       "      <td>9.539905e-08</td>\n",
       "      <td>1.430986e-07</td>\n",
       "      <td>1.907981e-07</td>\n",
       "      <td>2.384976e-07</td>\n",
       "      <td>2.861971e-07</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.630187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001_10003</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>86.14415</td>\n",
       "      <td>-4.999990e-01</td>\n",
       "      <td>-8.660243e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-8.660276e-01</td>\n",
       "      <td>-4.999982e-01</td>\n",
       "      <td>-6.636076e-06</td>\n",
       "      <td>0.500006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499996</td>\n",
       "      <td>-0.866026</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.866022</td>\n",
       "      <td>-0.500008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.866027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.155393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds          y       sin1_12       sin2_12  \\\n",
       "0  20001_10001 2019-11-01  236.65556 -4.999990e-01 -8.660243e-01   \n",
       "1  20001_10001 2019-12-01  180.21938  4.769952e-08  9.539905e-08   \n",
       "2  20001_10002 2019-11-01   45.61495 -4.999990e-01 -8.660243e-01   \n",
       "3  20001_10002 2019-12-01  113.33165  4.769952e-08  9.539905e-08   \n",
       "4  20001_10003 2019-11-01   86.14415 -4.999990e-01 -8.660243e-01   \n",
       "\n",
       "        sin3_12       sin4_12       sin5_12       sin6_12   sin7_12  ...  \\\n",
       "0 -1.000000e+00 -8.660276e-01 -4.999982e-01 -6.636076e-06  0.500006  ...   \n",
       "1  1.430986e-07  1.907981e-07  2.384976e-07  2.861971e-07 -0.000007  ...   \n",
       "2 -1.000000e+00 -8.660276e-01 -4.999982e-01 -6.636076e-06  0.500006  ...   \n",
       "3  1.430986e-07  1.907981e-07  2.384976e-07  2.861971e-07 -0.000007  ...   \n",
       "4 -1.000000e+00 -8.660276e-01 -4.999982e-01 -6.636076e-06  0.500006  ...   \n",
       "\n",
       "    cos4_12   cos5_12  cos6_12   cos7_12   cos8_12   cos9_12  cos10_12  \\\n",
       "0 -0.499996 -0.866026     -1.0 -0.866022 -0.500008  0.000005  0.500004   \n",
       "1  1.000000  1.000000      1.0  1.000000  1.000000  1.000000  1.000000   \n",
       "2 -0.499996 -0.866026     -1.0 -0.866022 -0.500008  0.000005  0.500004   \n",
       "3  1.000000  1.000000      1.0  1.000000  1.000000  1.000000  1.000000   \n",
       "4 -0.499996 -0.866026     -1.0 -0.866022 -0.500008  0.000005  0.500004   \n",
       "\n",
       "   cos11_12  cos12_12  LGBMRegressor  \n",
       "0  0.866027       1.0      52.923027  \n",
       "1  1.000000       1.0      71.890963  \n",
       "2  0.866027       1.0      23.000294  \n",
       "3  1.000000       1.0      26.630187  \n",
       "4  0.866027       1.0      25.155393  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validacion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f7ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " M√âTRICAS DE RENDIMIENTO DEL MODELO\n",
      "========================================\n",
      "Error Absoluto Medio (MAE):       0.11 unidades\n",
      "Ra√≠z del Error Cuadr√°tico (RMSE): 1.31 unidades\n",
      "Error Porcentual Absoluto (MAPE): 15300804610616704.00%\n",
      "Coeficiente de Determinaci√≥n (R¬≤): 0.40\n",
      "========================================\n",
      "\n",
      "Interpretaci√≥n:\n",
      "- En promedio, el modelo se equivoca en 0.11 toneladas (o la unidad que est√©s usando).\n",
      "- El error porcentual promedio es de 15300804610616704.00%.\n",
      "- Un R¬≤ de 0.40 indica qu√© proporci√≥n de la varianza de los datos es explicada por el modelo (m√°s cercano a 1 es mejor).\n"
     ]
    }
   ],
   "source": [
    "# 1. Extraer los valores reales y las predicciones del DataFrame\n",
    "y_real = resultados_validacion['y']\n",
    "y_pred = resultados_validacion['LGBMRegressor']\n",
    "\n",
    "# 2. Calcular las m√©tricas\n",
    "mae = mean_absolute_error(y_real, y_pred)\n",
    "mse = mean_squared_error(y_real, y_pred) # Calculamos el MSE primero\n",
    "rmse = np.sqrt(mse) # Luego calculamos su ra√≠z cuadrada para obtener el RMSE\n",
    "mape = mean_absolute_percentage_error(y_real, y_pred)\n",
    "r2 = r2_score(y_real, y_pred)\n",
    "\n",
    "\n",
    "# 3. Imprimir los resultados de forma clara\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" M√âTRICAS DE RENDIMIENTO DEL MODELO\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Error Absoluto Medio (MAE):       {mae:.2f} unidades\")\n",
    "print(f\"Ra√≠z del Error Cuadr√°tico (RMSE): {rmse:.2f} unidades\")\n",
    "print(f\"Error Porcentual Absoluto (MAPE): {mape:.2%}\")\n",
    "print(f\"Coeficiente de Determinaci√≥n (R¬≤): {r2:.2f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"\\nInterpretaci√≥n:\")\n",
    "print(f\"- En promedio, el modelo se equivoca en {mae:.2f} toneladas (o la unidad que est√©s usando).\")\n",
    "print(f\"- El error porcentual promedio es de {mape:.2%}.\")\n",
    "print(f\"- Un R¬≤ de {r2:.2f} indica qu√© proporci√≥n de la varianza de los datos es explicada por el modelo (m√°s cercano a 1 es mejor).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157b20b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " PARTE 2: PREDICCI√ìN FINAL PARA 202002\n",
      "============================================================\n",
      "\n",
      "Re-entrenando el modelo con todos los datos (9460980 filas) hasta 2019-12-01...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 6307320, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.114459\n",
      "\n",
      "--- ¬°PREDICCI√ìN FINAL PARA 202001 Y 202002! ---\n",
      "          unique_id         ds  LGBMRegressor\n",
      "0       20001_10001 2020-01-01      82.669177\n",
      "1       20001_10001 2020-02-01      78.726539\n",
      "2       20001_10002 2020-01-01      15.585885\n",
      "3       20001_10002 2020-02-01      14.842661\n",
      "4       20001_10003 2020-01-01      82.669177\n",
      "...             ...        ...            ...\n",
      "525605  21276_10462 2020-02-01       0.010059\n",
      "525606  21276_10495 2020-01-01       0.007369\n",
      "525607  21276_10495 2020-02-01       0.010059\n",
      "525608  21276_10550 2020-01-01       0.007369\n",
      "525609  21276_10550 2020-02-01       0.010059\n",
      "\n",
      "[525610 rows x 3 columns]\n",
      "\n",
      "--- Valor predicho espec√≠ficamente para 2020-02 ---\n",
      "          unique_id         ds  LGBMRegressor\n",
      "1       20001_10001 2020-02-01      78.726539\n",
      "3       20001_10002 2020-02-01      14.842661\n",
      "5       20001_10003 2020-02-01      78.726539\n",
      "7       20001_10004 2020-02-01      78.726539\n",
      "9       20001_10005 2020-02-01      12.762514\n",
      "...             ...        ...            ...\n",
      "525601  21276_10428 2020-02-01       0.010059\n",
      "525603  21276_10456 2020-02-01       0.010059\n",
      "525605  21276_10462 2020-02-01       0.010059\n",
      "525607  21276_10495 2020-02-01       0.010059\n",
      "525609  21276_10550 2020-02-01       0.010059\n",
      "\n",
      "[262805 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# PARTE 2: APLICACI√ìN REAL (Predecir 202002 con datos hasta 201912)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" PARTE 2: PREDICCI√ìN FINAL PARA 202002\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 7. Entrenar el modelo con TODOS los datos disponibles hasta 2019-12\n",
    "# Usamos el DataFrame completo 'df_final' que contiene todos los datos.\n",
    "print(f\"\\nRe-entrenando el modelo con todos los datos ({df_final.shape[0]} filas) hasta {df_final['ds'].max().date()}...\")\n",
    "\n",
    "# Re-entrenamos el mismo modelo (o uno nuevo con la misma config) con todos los datos\n",
    "# para obtener la mejor predicci√≥n posible.\n",
    "fcst.fit(df_final)\n",
    "\n",
    "# 8. Predecir 2 meses hacia el futuro para obtener 202001 y 202002\n",
    "predicciones_finales = fcst.predict(h=2)\n",
    "\n",
    "print(\"\\n--- ¬°PREDICCI√ìN FINAL PARA 202001 Y 202002! ---\")\n",
    "print(predicciones_finales)\n",
    "\n",
    "# Filtramos para ver el resultado que te interesa\n",
    "prediccion_target = predicciones_finales[predicciones_finales['ds'] == '2020-02-01']\n",
    "print(\"\\n--- Valor predicho espec√≠ficamente para 2020-02 ---\")\n",
    "print(prediccion_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c62f2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001_10001</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>78.726539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001_10002</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>14.842661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20001_10003</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>78.726539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20001_10004</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>78.726539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20001_10005</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>12.762514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds  LGBMRegressor\n",
       "1  20001_10001 2020-02-01      78.726539\n",
       "3  20001_10002 2020-02-01      14.842661\n",
       "5  20001_10003 2020-02-01      78.726539\n",
       "7  20001_10004 2020-02-01      78.726539\n",
       "9  20001_10005 2020-02-01      12.762514"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e249d7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1009.024483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>666.042483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>747.234118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>544.151167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>544.287563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  LGBMRegressor\n",
       "0       20001    1009.024483\n",
       "1       20002     666.042483\n",
       "2       20003     747.234118\n",
       "3       20004     544.151167\n",
       "4       20005     544.287563"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar product_id de unique_id y sumar LGBMRegressor por product_id\n",
    "df_pred_sum = prediccion_target.copy()\n",
    "df_pred_sum['product_id'] = df_pred_sum['unique_id'].str.split('_').str[0].astype(int)\n",
    "df_pred_sum_grouped = df_pred_sum.groupby('product_id', as_index=False)['LGBMRegressor'].sum()\n",
    "df_pred_sum_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed8f3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar la columna y exportar a CSV\n",
    "df_pred_sum_grouped.rename(columns={'LGBMRegressor': 'tn'}, inplace=True)\n",
    "df_pred_sum_grouped.to_csv('prediccion_tn_por_producto_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
