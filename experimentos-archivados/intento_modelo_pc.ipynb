{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f255cb3c",
   "metadata": {},
   "source": [
    "# Predicción de despacho de productos\n",
    "## Alternativa 1: Modelo por cada producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d301a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('../data/data.db')\n",
    "# df_sellin = pd.read_sql_query(\"SELECT * FROM sellin WHERE product_id in (select product_id from product_id_kaggle);\", conn)\n",
    "df = pd.read_csv('../data/sell-in.txt', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo de texto con un valor por fila\n",
    "product_ids_apredecir = pd.read_csv('../data/product_id_apredecir201912.txt', names=['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f21dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que los tipos coincidan para la comparación\n",
    "# Elimina la primera fila si contiene el nombre de la columna como valor\n",
    "product_ids_list = product_ids_apredecir[product_ids_apredecir['product_id'] != 'product_id']['product_id'].astype(int).tolist()\n",
    "df_filtrado = df[df['product_id'].isin(product_ids_list)]\n",
    "df_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtrado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_products = df['product_id'].nunique()\n",
    "print(f\"Number of distinct products: {num_distinct_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02590db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_df = df.pivot_table(\n",
    "    index=['product_id','customer_id'],\n",
    "    columns='periodo',\n",
    "    values='tn'\n",
    ").reset_index()\n",
    "\n",
    "pivot_df.columns.name = None\n",
    "pivot_df = pivot_df.rename_axis(None, axis=1)\n",
    "\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043eccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f51d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all columns except 'product_id' and 'customer_id' are null\n",
    "cols_to_check = pivot_df.columns.difference(['product_id', 'customer_id'])\n",
    "pivot_df = pivot_df.dropna(subset=cols_to_check, how='all')\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efee091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una copia para no modificar el original\n",
    "pivot_df_interpolado = pivot_df.copy()\n",
    "\n",
    "# Procesamos cada fila individualmente\n",
    "for idx, row in pivot_df_interpolado.iterrows():\n",
    "    values = row[2:]  # Excluye product_id y customer_id\n",
    "    # Encuentra el primer índice no nulo\n",
    "    first_valid = values.first_valid_index()\n",
    "    if first_valid is not None:\n",
    "        # Todos los valores después del primer dato válido: reemplaza NaN por 0\n",
    "        mask = values.index.get_loc(first_valid)\n",
    "        after_first = values.index[mask:]\n",
    "        # Solo reemplaza NaN por 0 en los valores después del primer dato válido\n",
    "        values.loc[after_first] = values.loc[after_first].fillna(0)\n",
    "        # Actualiza la fila en el DataFrame\n",
    "        pivot_df_interpolado.loc[idx, values.index] = values\n",
    "\n",
    "pivot_df_interpolado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el DataFrame pivot_df_interpolado en un archivo CSV\n",
    "pivot_df_interpolado.to_csv('../data/pivot_df_interpolado.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e29630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción para product_id=20001 en 2019-12: 1.39474\n",
      "Valor real: 19.60368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nespina/Elements/maestriacd/austral/labo_3/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/media/nespina/Elements/maestriacd/austral/labo_3/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "i = 20001\n",
    "# 20001.0\t10005.0\t\n",
    "# serie = pivot_df_interpolado[(pivot_df_interpolado['product_id'] == 20001) & (pivot_df_interpolado['customer_id'] == 10001)].iloc[0, 2:]  # Exclude 'product_id' and 'customer_id' columns\n",
    "serie = pivot_df_interpolado[(pivot_df_interpolado['product_id'] == 20001) & (pivot_df_interpolado['customer_id'] == 10005)].iloc[0, 2:]  # Exclude 'product_id' and 'customer_id' columns\n",
    "serie = serie.dropna()\n",
    "\n",
    "# Convert index to datetime for SARIMAX\n",
    "# Assuming your index is in 'YYYYMM' format\n",
    "serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "serie = serie.sort_index()\n",
    "\n",
    "# Define training and testing periods\n",
    "train_end_date = '2019-10-31'\n",
    "test_date = '2019-12-01' # For prediction\n",
    "\n",
    "# Split data\n",
    "train_data = serie[serie.index <= train_end_date]\n",
    "test_data = serie[serie.index == test_date]\n",
    "\n",
    "\n",
    "# order = (1,1,1)\n",
    "# seasonal_order = (2,1,0,4)  # S=4 para capturar la estacionalidad de las estaciones (trimestres)\n",
    "\n",
    "# order = (1,1,1)\n",
    "# seasonal_order = (1,1,1,4)  # S=4 para capturar la estacionalidad de las estaciones (trimestres)\n",
    "\n",
    "# Puedes agregar más combinaciones de parámetros válidos para SARIMAX.\n",
    "# Algunos ejemplos comunes para series mensuales con estacionalidad trimestral (S=4) o anual (S=12):\n",
    "\n",
    "param_space = {\n",
    "    'order': Categorical([\n",
    "        (1,1,1), (2,1,1), (1,1,2), (2,1,2), (0,1,1), (1,0,1)\n",
    "    ]),\n",
    "    'seasonal_order': Categorical([\n",
    "        (1,1,0,4), (1,1,1,4), (2,1,0,4), (0,1,1,4), (1,0,1,4),\n",
    "        (1,1,0,12), (1,1,1,12), (2,1,0,12)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and fit the SARIMAX model\n",
    "# 'enforce_stationarity=False' and 'enforce_invertibility=False' can help with convergence\n",
    "model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "model_fit = model.fit(disp=False) # disp=False to suppress optimization output\n",
    "\n",
    "# Make prediction for December 2019\n",
    "start_index = pd.to_datetime(test_date)\n",
    "end_index = pd.to_datetime(test_date)\n",
    "\n",
    "# Predict using the fitted model\n",
    "pred_201912 = model_fit.predict(start=start_index, end=end_index)\n",
    "\n",
    "print(f\"Predicción para product_id={i} en 2019-12: {pred_201912.iloc[0]:.5f}\")\n",
    "\n",
    "if not test_data.empty:\n",
    "    print(f\"Valor real: {test_data.iloc[0]:.5f}\")\n",
    "    # Optional: Calculate and print RMSE for evaluation\n",
    "    # rmse = np.sqrt(mean_squared_error(test_data, pred_201912))\n",
    "    # print(f\"RMSE: {rmse:.5f}\")\n",
    "else:\n",
    "    print(\"No hay valor real disponible para comparación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20001\n",
    "# 20001.0\t10005.0\t\n",
    "# serie = pivot_df_interpolado[(pivot_df_interpolado['product_id'] == 20001) & (pivot_df_interpolado['customer_id'] == 10001)].iloc[0, 2:]  # Exclude 'product_id' and 'customer_id' columns\n",
    "serie = pivot_df_interpolado[(pivot_df_interpolado['product_id'] == 20001) & (pivot_df_interpolado['customer_id'] == 10005)].iloc[0, 2:]  # Exclude 'product_id' and 'customer_id' columns\n",
    "serie = serie.dropna()\n",
    "\n",
    "# Convert index to datetime for SARIMAX\n",
    "# Assuming your index is in 'YYYYMM' format\n",
    "serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "serie = serie.sort_index()\n",
    "\n",
    "# Define training and testing periods\n",
    "train_end_date = '2019-10-31'\n",
    "test_date = '2019-12-01' # For prediction\n",
    "\n",
    "# Split data\n",
    "train_data = serie[serie.index <= train_end_date]\n",
    "test_data = serie[serie.index == test_date]\n",
    "\n",
    "\n",
    "\n",
    "param_space = {\n",
    "    'order': Categorical([\n",
    "        (1,1,1), (2,1,1), (1,1,2), (2,1,2), (0,1,1), (1,0,1)\n",
    "    ]),\n",
    "    'seasonal_order': Categorical([\n",
    "        (1,1,0,4), (1,1,1,4), (2,1,0,4), (0,1,1,4), (1,0,1,4),\n",
    "        (1,1,0,12), (1,1,1,12), (2,1,0,12)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and fit the SARIMAX model\n",
    "# 'enforce_stationarity=False' and 'enforce_invertibility=False' can help with convergence\n",
    "model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "model_fit = model.fit(disp=False) # disp=False to suppress optimization output\n",
    "\n",
    "# Make prediction for December 2019\n",
    "start_index = pd.to_datetime(test_date)\n",
    "end_index = pd.to_datetime(test_date)\n",
    "\n",
    "# Predict using the fitted model\n",
    "pred_201912 = model_fit.predict(start=start_index, end=end_index)\n",
    "\n",
    "print(f\"Predicción para product_id={i} en 2019-12: {pred_201912.iloc[0]:.5f}\")\n",
    "\n",
    "if not test_data.empty:\n",
    "    print(f\"Valor real: {test_data.iloc[0]:.5f}\")\n",
    "    # Optional: Calculate and print RMSE for evaluation\n",
    "    # rmse = np.sqrt(mean_squared_error(test_data, pred_201912))\n",
    "    # print(f\"RMSE: {rmse:.5f}\")\n",
    "else:\n",
    "    print(\"No hay valor real disponible para comparación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780abdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_2500 = pivot_df_interpolado.head(2500).copy()\n",
    "df_first_2500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = (1,1,1)\n",
    "seasonal_order = (2,1,0,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "for idx, row in df_first_2500.iterrows():\n",
    "    print(f\"Processing index: {idx}\")\n",
    "    product_id = row['product_id']\n",
    "    customer_id = row['customer_id']\n",
    "    serie = row[2:]\n",
    "    serie = serie.dropna()\n",
    "    if len(serie) < 8 or '201912' not in serie.index.astype(str):\n",
    "        continue\n",
    "\n",
    "    # Convertir el índice a fechas\n",
    "    serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "    serie = serie.sort_index()\n",
    "\n",
    "    # Definir periodos de train y test\n",
    "    train_end_date = '2019-10-31'\n",
    "    test_date = '2019-12-01'\n",
    "\n",
    "    train_data = serie[serie.index <= train_end_date]\n",
    "    test_data = serie[serie.index == test_date]\n",
    "\n",
    "    if len(train_data) < 8 or test_data.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "        pred_201912 = model_fit.predict(start=pd.to_datetime(test_date), end=pd.to_datetime(test_date)).iloc[0]\n",
    "        real_201912 = test_data.iloc[0]\n",
    "        resultados.append({\n",
    "            'product_id': product_id,\n",
    "            'customer_id': customer_id,\n",
    "            'sarimax_pred_201912': pred_201912,\n",
    "            'real_201912': real_201912\n",
    "        })\n",
    "    except Exception:\n",
    "\n",
    "        continue\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7342097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el error porcentual absoluto medio (MAPE) en sarimax_pred_201912\n",
    "mape_df_resultados = np.mean(np.abs((df_resultados['real_201912'] - df_resultados['sarimax_pred_201912']) / df_resultados['real_201912'])) * 100\n",
    "print(f\"Error porcentual absoluto medio (MAPE) en df_resultados: {mape_df_resultados:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28394de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Wrapper para SARIMAX compatible con sklearn\n",
    "class SARIMAXWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, order=(1,1,1), seasonal_order=(1,1,0,4)):\n",
    "        self.order = order\n",
    "        self.seasonal_order = seasonal_order\n",
    "        self.model_ = None\n",
    "        self.model_fit_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # SARIMAX espera un índice de fechas\n",
    "        self.model_ = SARIMAX(y, order=self.order, seasonal_order=self.seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        self.model_fit_ = self.model_.fit(disp=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X can be a 2D array (n_samples, 1) or 1D array of timestamps\n",
    "        # Convert to 1D array of pandas Timestamps\n",
    "        dates = pd.to_datetime(np.array(X).flatten())\n",
    "        preds = []\n",
    "        for date in dates:\n",
    "            pred = self.model_fit_.predict(start=date, end=date)\n",
    "            preds.append(pred.iloc[0])\n",
    "        return np.array(preds)\n",
    "\n",
    "# Espacio de búsqueda\n",
    "param_space = {\n",
    "    'order': Categorical([(1,1,1), (2,1,1), (1,1,2)]),\n",
    "    'seasonal_order': Categorical([(1,1,0,4), (1,1,1,4), (2,1,0,4)])\n",
    "}\n",
    "\n",
    "# Prepara los datos para sklearn (X: fechas, y: valores)\n",
    "X_train_sklearn = train_data.index.values.reshape(-1, 1)\n",
    "y_train_sklearn = train_data.values\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    SARIMAXWrapper(),\n",
    "    param_space,\n",
    "    n_iter=10,\n",
    "    cv=[(np.arange(len(X_train_sklearn)), np.arange(len(X_train_sklearn)))],  # No split, solo fit\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt.fit(X_train_sklearn, y_train_sklearn)\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "# Predicción para diciembre 2019\n",
    "pred_201912 = best_model.predict(np.array([start_index]))[0]\n",
    "\n",
    "print(f\"Predicción optimizada para product_id={i} en 2019-12: {pred_201912:.5f}\")\n",
    "if not test_data.empty:\n",
    "    print(f\"Valor real: {test_data.iloc[0]:.5f}\")\n",
    "else:\n",
    "    print(\"No hay valor real disponible para comparación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_preds = []\n",
    "sarimax_real = []\n",
    "product_ids = []\n",
    "\n",
    "for prod_id in pivot_df['product_id']:\n",
    "    serie = pivot_df[pivot_df['product_id'] == prod_id].iloc[0, 1:]\n",
    "    serie = serie.dropna()\n",
    "    if len(serie) < 8 or 201912 not in serie.index:\n",
    "        continue  # Necesitamos suficientes datos y valor real en 201912\n",
    "\n",
    "    # Convertir el índice a fechas para SARIMAX\n",
    "    serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "\n",
    "    # Entrenar hasta octubre 2019\n",
    "    train_data = serie[serie.index <= '2019-10-31']\n",
    "    test_data = serie[serie.index == '2019-12-01']\n",
    "\n",
    "    try:\n",
    "        model = SARIMAX(train_data, order=(1,1,1), seasonal_order=(1,1,0,4),\n",
    "                        enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "        pred = model_fit.predict(start=pd.to_datetime('2019-12-01'), end=pd.to_datetime('2019-12-01'))\n",
    "        sarimax_preds.append(pred.iloc[0])\n",
    "        sarimax_real.append(test_data.iloc[0])\n",
    "        product_ids.append(prod_id)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "df_sarimax_pred = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'sarimax_pred_201912': sarimax_preds,\n",
    "    'real_201912': sarimax_real\n",
    "})\n",
    "\n",
    "df_sarimax_pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el error porcentual absoluto medio (MAPE) entre las predicciones SARIMAX y los valores reales\n",
    "mape_sarimax = np.mean(np.abs((df_sarimax_pred['real_201912'] - df_sarimax_pred['sarimax_pred_201912']) / df_sarimax_pred['real_201912'])) * 100\n",
    "print(f\"Error porcentual absoluto medio (MAPE) SARIMAX: {mape_sarimax:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# Selecciona el producto i (por ejemplo, product_id = 20001)\n",
    "i = 20003\n",
    "serie = pivot_df[pivot_df['product_id'] == i].iloc[0, 1:]  # Excluye la columna product_id\n",
    "serie = serie.dropna()\n",
    "\n",
    "# Prepara los datos: X = mes (como entero), y = tn\n",
    "X = np.array(serie.index.astype(int)).reshape(-1, 1)\n",
    "y = serie.values\n",
    "\n",
    "# Train: hasta octubre 2019 (201910)\n",
    "train_mask = X.flatten() <= 201910\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "\n",
    "# Test: diciembre 2019 (201912)\n",
    "test_mask = X.flatten() == 201912\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# Modelo simple: regresión lineal sobre el tiempo\n",
    "# model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=250, max_depth=5, min_samples_split=8, min_samples_leaf=1, max_features='sqrt', bootstrap=True)\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=250, max_depth=5, min_samples_split=8, min_samples_leaf=1, max_features='sqrt', bootstrap=True)\n",
    "\n",
    "# model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción para diciembre 2019 (201912)\n",
    "pred_201912 = model.predict(np.array([[201912]]))[0]\n",
    "\n",
    "print(f\"Predicción para product_id={i} en 2019-12: {pred_201912:.5f}\")\n",
    "if len(y_test) > 0:\n",
    "    print(f\"Valor real: {y_test[0]:.5f}\")\n",
    "else:\n",
    "    print(\"No hay valor real disponible para comparación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "iter = 0\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_space = {\n",
    "    'n_estimators': Categorical([50, 100, 150, 200, 250, 300]),#Integer(50, 400),\n",
    "    'max_depth': Categorical([1, 5, 10, 20]),\n",
    "    'min_samples_split':  Categorical([2, 4, 6, 8, 10]),\n",
    "    'min_samples_leaf':  Categorical([1, 3, 5, 7]),\n",
    "    'max_features': Categorical(['sqrt', 'log2']),\n",
    "    'bootstrap': Categorical([True])\n",
    "}\n",
    "\n",
    "\n",
    "# Optimización bayesiana con logging\n",
    "opt = BayesSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_space,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "model = opt.best_estimator_\n",
    "\n",
    "# Predicción para diciembre 2019 (201912)\n",
    "pred_201912 = model.predict(np.array([[201912]]))[0]\n",
    "\n",
    "print(f\"Predicción para product_id={i} en 2019-12: {pred_201912:.5f}\")\n",
    "if len(y_test) > 0:\n",
    "    print(f\"Valor real: {y_test[0]:.5f}\")\n",
    "else:\n",
    "    print(\"No hay valor real disponible para comparación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario para almacenar las predicciones\n",
    "predicciones = {}\n",
    "\n",
    "for prod_id in pivot_df['product_id']:\n",
    "    serie = pivot_df[pivot_df['product_id'] == prod_id].iloc[0, 1:]  # Excluye la columna product_id\n",
    "    serie = serie.dropna()\n",
    "    if len(serie) < 2:\n",
    "        continue  # No se puede ajustar un modelo con menos de 2 puntos\n",
    "\n",
    "    X_prod = np.array(serie.index.astype(int)).reshape(-1, 1)\n",
    "    y_prod = serie.values\n",
    "\n",
    "    # Train: hasta octubre 2019 (201910)\n",
    "    train_mask = X_prod.flatten() <= 201910\n",
    "    X_train_prod, y_train_prod = X_prod[train_mask], y_prod[train_mask]\n",
    "\n",
    "    # Modelo simple: regresión lineal sobre el tiempo\n",
    "    if len(X_train_prod) < 2:\n",
    "        continue  # No se puede ajustar un modelo con menos de 2 puntos\n",
    "\n",
    "    # model_prod = LinearRegression()\n",
    "    model_prod = RandomForestRegressor(random_state=42, n_estimators=250, max_depth=5, min_samples_split=8, min_samples_leaf=1, max_features='sqrt', bootstrap=True)\n",
    "    model_prod.fit(X_train_prod, y_train_prod)\n",
    "\n",
    "    # Predicción para diciembre 2019 (201912)\n",
    "    pred_201912 = model_prod.predict(np.array([[201912]]))[0]\n",
    "    predicciones[prod_id] = pred_201912\n",
    "\n",
    "# Convertimos el diccionario a DataFrame para visualizar\n",
    "df_predicciones = pd.DataFrame(list(predicciones.items()), columns=['product_id', 'pred_201912'])\n",
    "df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calcula el accuracy de las predicciones usando el error absoluto medio (MAE) y el error cuadrático medio (RMSE)\n",
    "# Solo para productos que tienen valor real en 201912\n",
    "\n",
    "# Extraer los valores reales de 201912 para cada producto\n",
    "valores_reales = df[df['periodo'] == 201912][['product_id', 'tn']]\n",
    "\n",
    "# Unir con las predicciones\n",
    "df_eval = pd.merge(df_predicciones, valores_reales, on='product_id', how='inner')\n",
    "\n",
    "# Calcular métricas\n",
    "\n",
    "mae = mean_absolute_error(df_eval['tn'], df_eval['pred_201912'])\n",
    "rmse = mean_squared_error(df_eval['tn'], df_eval['pred_201912'], squared=False)\n",
    "\n",
    "print(f\"MAE (Error absoluto medio): {mae:.4f}\")\n",
    "print(f\"RMSE (Raíz del error cuadrático medio): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c23135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((df_eval['tn'] - df_eval['pred_201912']) / df_eval['tn'])) * 100\n",
    "print(f\"MAPE (Error porcentual absoluto medio): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desvío promedio porcentual de las predicciones respecto a los valores reales\n",
    "desvio_promedio = np.mean(np.abs(df_eval['pred_201912'] - df_eval['tn']) / df_eval['tn']) * 100\n",
    "print(f\"Desvío promedio porcentual: {desvio_promedio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bdb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Selecciona la serie temporal del producto 20001\n",
    "serie_20001 = pivot_df[pivot_df['product_id'] == 20001].iloc[0, 1:]  # Excluye la columna product_id\n",
    "serie_20001 = serie_20001.dropna()\n",
    "\n",
    "# Convierte el índice a periodo de fecha para la serie temporal\n",
    "serie_20001.index = pd.to_datetime(serie_20001.index.astype(str), format='%Y%m')\n",
    "\n",
    "# Ajusta el modelo SARIMAX considerando estacionalidad trimestral (4 meses por estación)\n",
    "model_sarimax = SARIMAX(serie_20001, order=(1,1,1), seasonal_order=(1,1,1,4))\n",
    "result_sarimax = model_sarimax.fit(disp=False)\n",
    "\n",
    "# Predicción para diciembre 2019\n",
    "pred_sarimax = result_sarimax.get_prediction(start=pd.to_datetime('2019-12-01'), end=pd.to_datetime('2019-12-01'))\n",
    "pred_value = pred_sarimax.predicted_mean.iloc[0]\n",
    "\n",
    "print(f\"Predicción SARIMAX para product_id=20001 en 2019-12: {pred_value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "sarimax_preds = []\n",
    "sarimax_real = []\n",
    "\n",
    "for prod_id in pivot_df['product_id']:\n",
    "    serie = pivot_df[pivot_df['product_id'] == prod_id].iloc[0, 1:]\n",
    "    serie = serie.dropna()\n",
    "    if len(serie) < 8 or 201912 not in serie.index:\n",
    "        continue  # Necesitamos suficientes datos y valor real en 201912\n",
    "\n",
    "    # Convertir el índice a fechas para SARIMAX\n",
    "    serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "\n",
    "    # SARIMAX simple, estacionalidad trimestral (4)\n",
    "    try:\n",
    "        model = SARIMAX(serie.iloc[:-1], order=(1,1,1), seasonal_order=(1,1,1,4))\n",
    "        result = model.fit(disp=False)\n",
    "        pred = result.get_prediction(start=serie.index[-1], end=serie.index[-1])\n",
    "        pred_value = pred.predicted_mean.iloc[0]\n",
    "        real_value = serie.iloc[-1]\n",
    "        sarimax_preds.append(pred_value)\n",
    "        sarimax_real.append(real_value)\n",
    "    except Exception as e:\n",
    "        continue  # Si falla el ajuste, lo salteamos\n",
    "\n",
    "sarimax_preds = np.array(sarimax_preds)\n",
    "sarimax_real = np.array(sarimax_real)\n",
    "sarimax_mape = np.mean(np.abs((sarimax_real - sarimax_preds) / sarimax_real)) * 100\n",
    "print(f\"MAPE SARIMAX (Error porcentual absoluto medio): {sarimax_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56472f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma total de toneladas reales para diciembre 2019\n",
    "total_real_dic2019 = valores_reales['tn'].sum()\n",
    "\n",
    "# Suma total de toneladas predichas para diciembre 2019 (usar df_predicciones)\n",
    "total_pred_dic2019 = df_predicciones['pred_201912'].sum()\n",
    "\n",
    "print(f\"Suma total real de toneladas en diciembre 2019: {total_real_dic2019:.2f}\")\n",
    "print(f\"Suma total predicha de toneladas en diciembre 2019: {total_pred_dic2019:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción Seasonal Naive Forecast para diciembre 2019 (2019-12-01)\n",
    "# Usamos el valor de diciembre 2018 (2018-12-01) como predicción para diciembre 2019\n",
    "\n",
    "# Proyección lineal simple usando solo los valores de 2017-12-01 y 2018-12-01 para cada producto\n",
    "linear_simple_preds = []\n",
    "linear_simple_real = []\n",
    "\n",
    "for prod_id in pivot_df['product_id']:\n",
    "    serie = pivot_df[pivot_df['product_id'] == prod_id].iloc[0, 1:]\n",
    "    serie = serie.dropna()\n",
    "    # Convertir el índice a fechas\n",
    "    serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "    # Necesitamos valores para 2017-12-01, 2018-12-01 y 2019-12-01\n",
    "    if (\n",
    "        pd.Timestamp('2017-12-01') in serie.index and\n",
    "        pd.Timestamp('2018-12-01') in serie.index and\n",
    "        pd.Timestamp('2019-12-01') in serie.index\n",
    "    ):\n",
    "        x = np.array([201712, 201812]).reshape(-1, 1)\n",
    "        y = np.array([serie.loc[pd.Timestamp('2017-12-01')], serie.loc[pd.Timestamp('2018-12-01')]])\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        pred = model.predict(np.array([[201912]]))[0]\n",
    "        real = serie.loc[pd.Timestamp('2019-12-01')]\n",
    "        linear_simple_preds.append(pred)\n",
    "        linear_simple_real.append(real)\n",
    "\n",
    "linear_simple_preds = np.array(linear_simple_preds)\n",
    "linear_simple_real = np.array(linear_simple_real)\n",
    "linear_simple_mape = np.mean(np.abs((linear_simple_real - linear_simple_preds) / linear_simple_real)) * 100\n",
    "print(f\"MAPE Linear Simple (Error porcentual absoluto medio): {linear_simple_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22545ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La predicción para product_id=20001 en 2019-12 usando el modelo de regresión lineal ya fue calculada en la celda 16:\n",
    "# pred_201912 = model.predict(np.array([[201912]]))[0]\n",
    "\n",
    "print(linear_simple_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pmdarima.auto_arima: Esta biblioteca puede encontrar automáticamente los mejores órdenes (p,d,q)(P,D,Q,S) para cada serie individual,\n",
    "# basándose en criterios como AIC o BIC. Esto podría mejorar la precisión por producto, pero aumentaría el tiempo de cómputo.\n",
    "\n",
    "# Python\n",
    "\n",
    "# Ejemplo con pmdarima para el caso actual\n",
    "\n",
    "autoarima_preds = []\n",
    "autoarima_real = []\n",
    "\n",
    "for prod_id in pivot_df['product_id']:\n",
    "    serie = pivot_df[pivot_df['product_id'] == prod_id].iloc[0, 1:]\n",
    "    serie = serie.dropna()\n",
    "    # Necesitamos al menos 8 datos y valor real en 201912\n",
    "    if len(serie) < 8 or 201912 not in serie.index:\n",
    "        continue\n",
    "\n",
    "    # Convertir el índice a fechas\n",
    "    serie.index = pd.to_datetime(serie.index.astype(str), format='%Y%m')\n",
    "\n",
    "    # Usar todos los datos menos el último (2019-12-01) para entrenar\n",
    "    train_serie = serie.iloc[:-1]\n",
    "    try:\n",
    "        auto_model = pm.auto_arima(\n",
    "            train_serie,\n",
    "            start_p=1, start_q=1,\n",
    "            max_p=3, max_q=3, m=4,\n",
    "            start_P=0, seasonal=True,\n",
    "            d=1, D=1, trace=False,\n",
    "            error_action='ignore',\n",
    "            suppress_warnings=True,\n",
    "            stepwise=True\n",
    "        )\n",
    "        pred = auto_model.predict(n_periods=1)[0]\n",
    "        real = serie.iloc[-1]\n",
    "        autoarima_preds.append(pred)\n",
    "        autoarima_real.append(real)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "autoarima_preds = np.array(autoarima_preds)\n",
    "autoarima_real = np.array(autoarima_real)\n",
    "autoarima_mape = np.mean(np.abs((autoarima_real - autoarima_preds) / autoarima_real)) * 100\n",
    "print(f\"MAPE Auto-ARIMA (Error porcentual absoluto medio): {autoarima_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las predicciones y los valores reales del método seasonal naive\n",
    "df_seasonal_naive = pd.DataFrame({\n",
    "    'preds': autoarima_preds,\n",
    "    'real': autoarima_real\n",
    "})\n",
    "\n",
    "df_seasonal_naive.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
